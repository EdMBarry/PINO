{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bccb6973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "from pyDOE import lhs\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "\n",
    "from torch.optim import Adam, SGD, LBFGS\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "117e4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_block(in_channel, out_channel):\n",
    "    block = nn.Sequential(\n",
    "        nn.Linear(in_channel, out_channel), \n",
    "        nn.Tanh()\n",
    "    )\n",
    "    return block\n",
    "\n",
    "class FCNet(nn.Module):\n",
    "    def __init__(self, layers=[2, 10, 1]):\n",
    "        super(FCNet, self).__init__()\n",
    "        fc_list = [linear_block(in_size, out_size) for in_size, out_size in zip(layers, layers[1:-1])]\n",
    "        fc_list.append(nn.Linear(layers[-2], layers[-1]))\n",
    "        self.fc = nn.Sequential(*fc_list)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d2f3840",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BurgerData(Dataset):\n",
    "    '''\n",
    "    members: \n",
    "        - t, x, Exact: raw data\n",
    "        - X, T: meshgrid \n",
    "        - X_star, u_star: flattened (x, t), u array\n",
    "        - lb, ub: lower bound and upper bound vector\n",
    "        - X_u, u: boundary condition data (x, t), u\n",
    "    '''\n",
    "    def __init__(self, datapath):\n",
    "        data = scipy.io.loadmat(datapath)\n",
    "\n",
    "        # raw 2D data\n",
    "        self.t = np.linspace(0,1,101) # (100,1)\n",
    "        self.x = np.linspace(0,1,128) # (256, 1)\n",
    "        self.Exact = np.real(data['output'][100,:,:]).T # (100, 256)\n",
    "\n",
    "        # Flattened sequence\n",
    "        self.get_flatten_data()\n",
    "        self.get_boundary_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.Exact.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_star[idx], self.u_star[idx]\n",
    "    \n",
    "    def get_flatten_data(self):\n",
    "        X, T = np.meshgrid(self.x, self.t)\n",
    "        self.X, self.T = X, T\n",
    "        self.X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None])) # \n",
    "        self.u_star = self.Exact.flatten()[:,None]\n",
    "        \n",
    "        self.lb = self.X_star.min(0) # lower bound of (x, t): 2-dimensional vector \n",
    "        self.ub = self.X_star.max(0) # upper bound of (x, t): 2-dimensional vector\n",
    "\n",
    "    def get_boundary_data(self):\n",
    "        xx1 = np.hstack((self.X[0:1,:].T, self.T[0:1,:].T))\n",
    "        uu1 = self.Exact[0:1,:].T\n",
    "        xx2 = np.hstack((self.X[:,0:1], self.T[:,0:1]))\n",
    "        uu2 = self.Exact[:,0:1]\n",
    "        xx3 = np.hstack((self.X[:,-1:], self.T[:,-1:]))\n",
    "        uu3 = self.Exact[:,-1:]\n",
    "        self.X_u = np.vstack([xx1, xx2, xx3])\n",
    "        self.u = np.vstack([uu1, uu2, uu3])\n",
    "    \n",
    "    def sample_xt(self, N=10000):\n",
    "        '''\n",
    "        Sample (x, t) pairs within the boundary\n",
    "        Return:\n",
    "            - X_f: (N, 2) array\n",
    "        '''\n",
    "        X_f = self.lb + (self.ub-self.lb)*lhs(2, N)\n",
    "        X_f = np.vstack((X_f, self.X_u))\n",
    "        return X_f\n",
    "\n",
    "    def sample_xu(self, N=100):\n",
    "        '''\n",
    "        Sample N points from boundary data\n",
    "        Return: \n",
    "            - X_u: (N, 2) array \n",
    "            - u: (N, 1) array\n",
    "        '''\n",
    "        idx =  np.random.choice(self.X_u.shape[0], N, replace=False)\n",
    "        X_u = self.X_u[idx, :]\n",
    "        u = self.u[idx,:]\n",
    "        return X_u, u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48fbbc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    count = 0\n",
    "    for p in model.parameters():\n",
    "        count += p.numel()\n",
    "    return count\n",
    "\n",
    "def requires_grad(model, flag=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag\n",
    "\n",
    "def zero_grad(params):\n",
    "    '''\n",
    "    set grad field to 0\n",
    "    '''\n",
    "    if isinstance(params, torch.Tensor):\n",
    "        if params.grad is not None:\n",
    "            params.grad.detach()\n",
    "            params.grad.zero_()\n",
    "    else:\n",
    "        for p in params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.detach()\n",
    "                p.grad.zero_()\n",
    "                \n",
    "def mse(X, Y):\n",
    "    loss = (X - Y) ** 2\n",
    "    return loss.mean()\n",
    "\n",
    "def PDELoss(model, x, t, nu, equation='B'):\n",
    "    '''\n",
    "    Compute the residual of PDE: \n",
    "        residual = u_t + u * u_x - nu * u_{xx} : (N,1)\n",
    "    \n",
    "    Params: \n",
    "        - model \n",
    "        - x, t: (x, t) pairs, (N, 2) tensor\n",
    "        - nu: constant of PDE\n",
    "        - equation: 'A' stands for Allen Cahn equation, 'B' stands for Burger's equation\n",
    "    Return: \n",
    "        - mean of residual : scalar \n",
    "    '''\n",
    "    u = model(torch.cat([x, t], dim=1))\n",
    "    # First backward to compute u_x (shape: N x 1), u_t (shape: N x 1)\n",
    "    grad_x, grad_t= autograd.grad(outputs=[u.sum()], inputs=[x, t], create_graph=True)\n",
    "    # grad_x = grad_xt[:, 0]\n",
    "    # grad_t = grad_xt[:, 1]\n",
    "\n",
    "    # Second backward to compute u_{xx} (shape N x 1)\n",
    "    \n",
    "    gradgrad_x, = autograd.grad(outputs=[grad_x.sum()], inputs=[x], create_graph=True)\n",
    "    # gradgrad_x = gradgrad[:, 0]\n",
    "    if equation == 'B':\n",
    "        residual = grad_t + u * grad_x - nu * gradgrad_x\n",
    "    elif equation == 'A':\n",
    "        residual = grad_t + 5 * u ** 3 - 5 * u - nu * gradgrad_x \n",
    "    return residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c6ca2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_u, u, X_f, gamma=1.0,\n",
    "          nu=1.0, num_epoch=100, equation='B',\n",
    "          device=torch.device('cpu'), optim='LBFGS'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = LBFGS(model.parameters(), \n",
    "                      lr=1.0, \n",
    "                      max_iter=50000, \n",
    "                      max_eval=50000, \n",
    "                      history_size=50,\n",
    "                      tolerance_grad=1e-5, \n",
    "                      tolerance_change=1.0 * np.finfo(float).eps,\n",
    "                      line_search_fn=\"strong_wolfe\")\n",
    "    # mse = nn.MSELoss()\n",
    "    # training stage\n",
    "    xts = torch.from_numpy(X_u).float().to(device)\n",
    "    us = torch.from_numpy(u).float().to(device)\n",
    "\n",
    "    xs = torch.from_numpy(X_f[:, 0:1]).float().to(device)\n",
    "    ts = torch.from_numpy(X_f[:, 1:2]).float().to(device)\n",
    "    xs.requires_grad = True\n",
    "    ts.requires_grad = True\n",
    "    iter = 0\n",
    "\n",
    "    def loss_closure():\n",
    "        nonlocal iter\n",
    "        iter = iter + 1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        zero_grad(xs)\n",
    "        zero_grad(ts)\n",
    "        # print(xs.grad)\n",
    "        # MSE loss of prediction error\n",
    "        # print(xts.shape)\n",
    "        pred_u = model(xts)\n",
    "        mse_u = mse(pred_u, us)\n",
    "        \n",
    "        # MSE loss of PDE constraint\n",
    "        f = PDELoss(model, xs, ts, nu, equation=equation)\n",
    "\n",
    "        mse_f = torch.mean(f ** 2)\n",
    "        loss = gamma * mse_u + mse_f\n",
    "        loss.backward()\n",
    "        \n",
    "        if iter % 100==0:\n",
    "            print('Iter: {}, total loss: {}, mse_u: {}, mse_f: {}'.\n",
    "                format(iter, loss.item(), mse_u.item(), mse_f.item()))\n",
    "        return loss\n",
    "    \n",
    "    optimizer.step(loss_closure)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fbed8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, x, t, nu):\n",
    "    '''\n",
    "    Params:\n",
    "        - model: model\n",
    "        - xt: (N, 2) tensor\n",
    "    Return: \n",
    "        - u: (N, 1) tensor\n",
    "        - residual: (N, 1) tensor\n",
    "    '''\n",
    "    model.eval()\n",
    "    \n",
    "    x.requires_grad = True\n",
    "    t.requires_grad = True\n",
    "\n",
    "    u = model(torch.cat([x, t], dim=1))\n",
    "\n",
    "    grad_x, grad_t = autograd.grad(outputs=u.sum(), inputs=[x, t], \n",
    "                                   create_graph=True)\n",
    "    gradgrad_x, = autograd.grad(outputs=grad_x.sum(), inputs=[x])\n",
    "\n",
    "    residual = grad_t + u * grad_x - nu * gradgrad_x\n",
    "    return u.detach(), residual.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb5f3162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LpLoss(object):\n",
    "    '''\n",
    "    loss function with rel/abs Lp loss\n",
    "    '''\n",
    "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
    "        super(LpLoss, self).__init__()\n",
    "\n",
    "        #Dimension and Lp-norm type are postive\n",
    "        assert d > 0 and p > 0\n",
    "\n",
    "        self.d = d\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def abs(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        #Assume uniform mesh\n",
    "        h = 1.0 / (x.size()[1] - 1.0)\n",
    "\n",
    "        all_norms = (h**(self.d/self.p))*torch.norm(x.view(num_examples,-1) - y.view(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(all_norms)\n",
    "            else:\n",
    "                return torch.sum(all_norms)\n",
    "\n",
    "        return all_norms\n",
    "\n",
    "    def rel(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n",
    "        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(diff_norms/y_norms)\n",
    "            else:\n",
    "                return torch.sum(diff_norms/y_norms)\n",
    "\n",
    "        return diff_norms/y_norms\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        return self.rel(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4753b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_plot(model, trainset, tag='default'):\n",
    "    myloss = LpLoss(size_average=True)\n",
    "    # Compute prediction and residual of network \n",
    "    X_star = trainset.X_star\n",
    "    target_u = torch.tensor(trainset.u_star).float().to(device).squeeze()\n",
    "\n",
    "    eval_x = torch.tensor(X_star[:, 0:1]).float().to(device)\n",
    "    eval_t = torch.tensor(X_star[:, 1:2]).float().to(device)\n",
    "\n",
    "    pred_u, residual = predict(model, eval_x, eval_t, nu)\n",
    "#     pred_u, residual = pred_u.squeeze(), residual.squeeze()\n",
    "    \n",
    "#     relative_error = torch.norm(pred_u - target_u) / torch.norm(target_u)\n",
    "    relative_error = myloss(pred_u, target_u)\n",
    "    print('Relative error ||pred_u - target_u||_2 / ||target_u||_2: {}'.format(relative_error.item()))\n",
    "    print('Averaged PDE L1 residual error: {}'.format(torch.abs(residual).mean().item()))\n",
    "\n",
    "#     #==== reshape pred_u to meshgrid for visualization =====\n",
    "#     u_2d = griddata(X_star, pred_u.cpu().numpy(), (trainset.X, trainset.T), method='cubic')\n",
    "#     error_2d = trainset.Exact - u_2d\n",
    "#     t = trainset.t\n",
    "#     x = trainset.x\n",
    "\n",
    "#     # absolute error plot\n",
    "#     plt.imshow(np.abs(error_2d.T), interpolation='nearest', cmap='Blues', \n",
    "#               extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "#               origin='lower', aspect='auto')\n",
    "#     plt.xlabel('$t$', fontsize=15)\n",
    "#     plt.ylabel('$x$', fontsize=15)\n",
    "#     plt.title('Absolute approximation error at each point')\n",
    "#     plt.colorbar()\n",
    "#     plt.savefig('abs_err-%s.png' % tag)\n",
    "#     plt.show()\n",
    "\n",
    "#     # Approximation at specific time slice\n",
    "#     tvalues = [25, 50, 75]\n",
    "#     fig, axes = plt.subplots(len(tvalues), 1, sharex=True)\n",
    "#     fig.set_size_inches(12, 8)\n",
    "#     for ax, tstep in zip(axes, tvalues):\n",
    "#         ax.plot(x, u_2d[tstep, :], 'r--', linewidth=3, label='Prediction', alpha=0.9)\n",
    "#         ax.plot(x, trainset.Exact[tstep, :], 'b-', linewidth=3, label='Exact', alpha=0.7)\n",
    "#         ax.set_title('t=0.%d' % tstep, fontsize=15)\n",
    "#         ax.set_ylabel('$u(x,t)$', fontsize=15)\n",
    "#     ax.set_xlabel('$x$', fontsize=15)\n",
    "#     ax.legend(loc='right')\n",
    "#     plt.savefig('timeslice-%s.png' % tag)\n",
    "\n",
    "#     fig, ax = plt.subplots()\n",
    "#     # residual error plot\n",
    "#     res_2d = griddata(X_star, residual.cpu().numpy(), (trainset.X, trainset.T), method='cubic')\n",
    "#     plt.imshow(res_2d.T, interpolation='nearest', cmap='RdBu', \n",
    "#                 extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "#                 origin='lower', aspect='auto')\n",
    "#     plt.xlabel('$t$', fontsize=15)\n",
    "#     plt.ylabel('$x$', fontsize=15)\n",
    "#     plt.colorbar()\n",
    "#     plt.savefig('pde-residual-%s.png' % tag)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06544331",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_u = 100\n",
    "N_f = 10000\n",
    "datapath = 'data/burgers_pino.mat'\n",
    "\n",
    "trainset = BurgerData(datapath)\n",
    "uxs, us = trainset.sample_xu(N_u)\n",
    "X_f = trainset.sample_xt(N_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8cd587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "nu = 0.01 / np.pi\n",
    "# config for FCN\n",
    "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
    "# config for Fourier net\n",
    "modes = 12\n",
    "width = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66cc16ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  3021\n",
      "Iter: 100, total loss: 0.0010602191323414445, mse_u: 0.0009893907699733973, mse_f: 7.082833326421678e-05\n",
      "Iter: 200, total loss: 0.0008900378597900271, mse_u: 0.0007325236219912767, mse_f: 0.00015751420869491994\n",
      "Iter: 300, total loss: 0.0008082585409283638, mse_u: 0.000623744388576597, mse_f: 0.0001845141377998516\n",
      "Iter: 400, total loss: 0.0007019194308668375, mse_u: 0.0004730932996608317, mse_f: 0.0002288261312060058\n",
      "Iter: 500, total loss: 0.00046493549598380923, mse_u: 0.0003211726143490523, mse_f: 0.00014376288163475692\n",
      "Iter: 600, total loss: 0.0003071909595746547, mse_u: 0.0002118288102792576, mse_f: 9.53621492953971e-05\n",
      "Iter: 700, total loss: 0.00023853438324294984, mse_u: 0.00017714808927848935, mse_f: 6.13863012404181e-05\n",
      "Iter: 800, total loss: 0.00021138555894140154, mse_u: 0.00015765933494549245, mse_f: 5.372622035793029e-05\n",
      "Iter: 900, total loss: 0.00018969639495480806, mse_u: 0.00014686949725728482, mse_f: 4.282690133550204e-05\n",
      "Iter: 1000, total loss: 0.00017389949061907828, mse_u: 0.0001438900944776833, mse_f: 3.0009397960384376e-05\n",
      "Iter: 1100, total loss: 0.00016201533435378224, mse_u: 0.00014138092228677124, mse_f: 2.0634406610042788e-05\n"
     ]
    }
   ],
   "source": [
    "fcn = FCNet(layers)\n",
    "print('Number of parameters: ', count_parameters(fcn))\n",
    "fcn = train(fcn, X_u=uxs, u=us, X_f=X_f, nu=nu, num_epoch=1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2dafd45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error ||pred_u - target_u||_2 / ||target_u||_2: 3.1248230934143066\n",
      "Averaged PDE L1 residual error: 0.002849587006494403\n"
     ]
    }
   ],
   "source": [
    "eval_plot(fcn, trainset, tag='FCN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0173a3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf7d07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
